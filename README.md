# ğŸš€ n8n RAG Automation using Ollama & Pinecone

A fully automated **Retrieval-Augmented Generation (RAG)** pipeline built with **n8n**, **Ollama (local LLMs)**, and **Pinecone Vector Database**.

This project demonstrates how to ingest documents, generate embeddings, store them in a vector database, and query them using an AI Agent with real context.

---

## âœ¨ Features

- ğŸ“ Automated document ingestion from Google Drive
- âœ‚ï¸ Intelligent document chunking
- ğŸ§  Embedding generation using local Ollama models
- ğŸ“¦ Scalable vector storage with Pinecone
- ğŸ’¬ Context-aware chat using n8n AI Agent
- ğŸ”’ Runs locally with no external LLM dependency

---
## ğŸ“‚ Folder Structure

```
n8n-rag-automation-ollama-pinecone/
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ file-ingestion-pipeline.json
â”‚   â””â”€â”€ rag-chat-automation.json
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ file-ingestion-workflow.png
â”‚   â””â”€â”€ rag-chat-workflow.png
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---

## ğŸ—ï¸ Architecture Overview

**File Ingestion Pipeline**
- Google Drive Trigger (file added/updated)
- File download
- Recursive Character Text Splitter
- Embeddings via `nomic-embed-text`
- Store vectors in Pinecone

**RAG Chat Pipeline**
- Chat trigger
- AI Agent (tool-enabled)
- Semantic search from Pinecone
- Context-aware responses using Llama 3.2

---

## ğŸ§  Models Used

| Purpose | Model |
|------|------|
| Chat / Agent | `llama3.2:latest` |
| Embeddings | `nomic-embed-text` |
| Embedding Dimension | `768` |
| Similarity Metric | `cosine` |

---

## âš™ï¸ Prerequisites

- n8n (local or Docker)
- Ollama installed
- Pinecone account
- Google Drive credentials (for ingestion)

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Install Ollama Models
```bash
ollama pull llama3.2
ollama pull nomic-embed-text

 ```



---
## ğŸŒŸ Final Notes

This project was built to explore how **automation, local LLMs, and vector databases** come together to form real-world AI systems.  
Everything here is designed to be **practical, transparent, and extensible**.

If this repository helps you learn, build, or experiment with **RAG pipelines**, feel free to fork it, adapt it, or improve it.

Contributions, suggestions, and discussions are always welcome.

â­ If you found this useful, consider starring the repo â€” it really helps!

Happy building ğŸš€
---
